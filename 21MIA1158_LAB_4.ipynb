{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4b8342c",
   "metadata": {},
   "source": [
    "Extract images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a519d09c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 403 frames and converted them to HSV.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    " \n",
    " \n",
    "def video_to_hsv_frames(video_path, output_folder):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    " \n",
    "    frame_count = 0\n",
    " \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    " \n",
    "        if not ret:\n",
    "            break\n",
    " \n",
    "        hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    " \n",
    "        hsv_frame_path = os.path.join(output_folder, f'frame_{frame_count:04d}.png')\n",
    "        cv2.imwrite(hsv_frame_path, hsv_frame)\n",
    " \n",
    "        frame_count += 1\n",
    " \n",
    "    cap.release()\n",
    "    print(f'Extracted {frame_count} frames and converted them to HSV.')\n",
    " \n",
    " \n",
    "video_path = r\"C:\\Users\\Radcoflex-Purchase\\Desktop\\COLLEGE\\SEM 7\\Image and Video Analytics\\lab 4/coke.mp4\"  \n",
    "output_folder = r\"C:\\Users\\Radcoflex-Purchase\\Desktop\\COLLEGE\\SEM 7\\Image and Video Analytics\\lab 4/cola\"  \n",
    " \n",
    "video_to_hsv_frames(video_path, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67d7d3e9",
   "metadata": {},
   "source": [
    "Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2981cf60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation completed and saved.\n"
     ]
    }
   ],
   "source": [
    "input_folder = r\"C:\\Users\\Radcoflex-Purchase\\Desktop\\COLLEGE\\SEM 7\\Image and Video Analytics\\lab 4\\cola\"\n",
    "output_folder = r\"C:\\Users\\Radcoflex-Purchase\\Desktop\\COLLEGE\\SEM 7\\Image and Video Analytics\\lab 4\\cola_segmented\"\n",
    "\n",
    "\n",
    "lower_green1 = (40, 100, 100)   \n",
    "upper_green1 = (80, 255, 255)   \n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        \n",
    "        frame = cv2.imread(os.path.join(input_folder, filename))\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        mask = cv2.inRange(hsv, lower_green1, upper_green1)\n",
    "        \n",
    "        cv2.imwrite(os.path.join(output_folder, f\"color_threshold_{filename}\"), mask)\n",
    "\n",
    "print(\"Segmentation completed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250741b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450ff9d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c720acf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7ed0d2d5",
   "metadata": {},
   "source": [
    "Track objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bc31601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "input_folder = r\"C:\\Users\\Radcoflex-Purchase\\Desktop\\COLLEGE\\SEM 7\\Image and Video Analytics\\lab 4\\cola_segmented\"\n",
    "output_folder = r\"C:\\Users\\Radcoflex-Purchase\\Desktop\\COLLEGE\\SEM 7\\Image and Video Analytics\\lab 4\\cola_track\"\n",
    "\n",
    "prev_centroids = []\n",
    "\n",
    "for filename in sorted(os.listdir(input_folder)):  \n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        frame = cv2.imread(os.path.join(input_folder, filename))\n",
    "\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        _, mask = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        curr_centroids = []\n",
    "        \n",
    "        for contour in contours:\n",
    "            if cv2.contourArea(contour) > 200:  \n",
    "                x, y, w, h = cv2.boundingRect(contour)\n",
    "                \n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "                \n",
    "                M = cv2.moments(contour)\n",
    "                if M[\"m00\"] != 0:\n",
    "                    cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "                    cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "                    curr_centroids.append((cX, cY))\n",
    "\n",
    "                    cv2.circle(frame, (cX, cY), 5, (255, 0, 0), -1)\n",
    "\n",
    "        if prev_centroids and curr_centroids:  \n",
    "            for prev_centroid in prev_centroids:\n",
    "                nearest_centroid = min(curr_centroids, key=lambda c: np.linalg.norm(np.array(c) - np.array(prev_centroid)))\n",
    "                \n",
    "                cv2.line(frame, prev_centroid, nearest_centroid, (0, 0, 255), 2)\n",
    "\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"tracked_{filename}\"), frame)\n",
    "\n",
    "        prev_centroids = curr_centroids\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3626998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreground-background segmentation completed and saved.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "input_folder = r\"C:\\Users\\Radcoflex-Purchase\\Desktop\\COLLEGE\\SEM 7\\Image and Video Analytics\\lab 4/cola_track\"\n",
    "output_folder = r\"C:\\Users\\Radcoflex-Purchase\\Desktop\\COLLEGE\\SEM 7\\Image and Video Analytics\\lab 4/cola_fore_back\"\n",
    "\n",
    "background_subtractor = cv2.createBackgroundSubtractorMOG2(history=50, varThreshold=70, detectShadows=True)\n",
    "\n",
    "for filename in sorted(os.listdir(input_folder)): \n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        frame = cv2.imread(os.path.join(input_folder, filename))\n",
    "\n",
    "        fg_mask = background_subtractor.apply(frame)\n",
    "\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "        fg_mask = cv2.morphologyEx(fg_mask, cv2.MORPH_OPEN, kernel)\n",
    "        fg_mask_3ch = cv2.cvtColor(fg_mask, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "        background = cv2.bitwise_and(frame, frame, mask=cv2.bitwise_not(fg_mask))\n",
    "        foreground = cv2.bitwise_and(frame, frame, mask=fg_mask)\n",
    "\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"background_{filename}\"), foreground)\n",
    "        cv2.imwrite(os.path.join(output_folder, f\"foreround_{filename}\"), background)\n",
    "\n",
    "print(\"Foreground-background segmentation completed and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db5a6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fee2983",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c66f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057d651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfc79a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bd47ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94203b60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9ae93e73",
   "metadata": {},
   "source": [
    "scene cut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a96c279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene cut detected at frame 10 (Pixel diff: 93.35308195891204, Hist diff: 0.030984378976063365)\n",
      "Scene cut detected at frame 43 (Pixel diff: 53.2844798900463, Hist diff: 0.8236799999363161)\n",
      "Scene cut detected at frame 76 (Pixel diff: 57.00165183738426, Hist diff: 0.1757649597841487)\n",
      "Scene cut detected at frame 78 (Pixel diff: 36.67390480324074, Hist diff: 0.965284872782859)\n",
      "Scene cut detected at frame 79 (Pixel diff: 57.86677915219907, Hist diff: 0.9639672718046816)\n",
      "Scene cut detected at frame 127 (Pixel diff: 49.65019133391203, Hist diff: 0.7543759063986122)\n",
      "Scene cut detected at frame 147 (Pixel diff: 89.03747432002315, Hist diff: 0.5082651700293114)\n",
      "Scene cut detected at frame 195 (Pixel diff: 39.39852394386574, Hist diff: 0.8788859145191895)\n",
      "Scene cut detected at frame 196 (Pixel diff: 68.46531105324074, Hist diff: 0.7563525293735641)\n",
      "Scene cut detected at frame 197 (Pixel diff: 63.73228479456019, Hist diff: 0.8575594195647827)\n",
      "Scene cut detected at frame 198 (Pixel diff: 61.507851924189815, Hist diff: 0.9548729693727581)\n",
      "Scene cut detected at frame 199 (Pixel diff: 80.46236798321759, Hist diff: -0.14204031546760149)\n",
      "Scene cut detected at frame 235 (Pixel diff: 31.32895941840278, Hist diff: 0.4801332209178088)\n",
      "Scene cut detected at frame 237 (Pixel diff: 68.99508608217593, Hist diff: 0.2981332667975029)\n",
      "Scene cut detected at frame 280 (Pixel diff: 64.34677445023148, Hist diff: 0.0908068683807343)\n",
      "Scene cut detected at frame 283 (Pixel diff: 38.48086841724537, Hist diff: 0.6463113632701823)\n",
      "Scene cut detected at frame 290 (Pixel diff: 35.08376953125, Hist diff: 0.8527726782745584)\n",
      "Scene cut detected at frame 295 (Pixel diff: 34.135944010416665, Hist diff: 0.973300131584236)\n",
      "Scene cut detected at frame 299 (Pixel diff: 30.332916666666666, Hist diff: 0.916028254010423)\n",
      "Scene cut detected at frame 300 (Pixel diff: 101.56248191550925, Hist diff: 0.2478120238662015)\n",
      "Scene cut detected at frame 301 (Pixel diff: 7.785528790509259, Hist diff: 0.44418036522853827)\n",
      "Scene cuts detected at frames: [10, 43, 76, 78, 79, 127, 147, 195, 196, 197, 198, 199, 235, 237, 280, 283, 290, 295, 299, 300, 301]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "input_folder = r\"C:\\Users\\Radcoflex-Purchase\\Desktop\\COLLEGE\\SEM 7\\Image and Video Analytics\\lab 4/cola\"\n",
    "\n",
    "\n",
    "pixel_diff_threshold = 30  \n",
    "hist_diff_threshold = 0.7 \n",
    "\n",
    "\n",
    "def compare_histograms(frame1, frame2):\n",
    "    hsv_frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2HSV)\n",
    "    hsv_frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    hist_frame1 = cv2.calcHist([hsv_frame1], [0, 1, 2], None, [8, 8, 8], [0, 180, 0, 256, 0, 256])\n",
    "    hist_frame2 = cv2.calcHist([hsv_frame2], [0, 1, 2], None, [8, 8, 8], [0, 180, 0, 256, 0, 256])\n",
    "    \n",
    "    cv2.normalize(hist_frame1, hist_frame1)\n",
    "    cv2.normalize(hist_frame2, hist_frame2)\n",
    "    \n",
    "    return cv2.compareHist(hist_frame1, hist_frame2, cv2.HISTCMP_CORREL)\n",
    "\n",
    "def compute_pixel_difference(frame1, frame2):\n",
    "    diff = cv2.absdiff(frame1, frame2)\n",
    "    mean_diff = np.mean(diff)\n",
    "    return mean_diff\n",
    "\n",
    "prev_frame = None\n",
    "frame_number = 0\n",
    "scene_cuts = []\n",
    "\n",
    "for filename in sorted(os.listdir(input_folder)): \n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        frame = cv2.imread(os.path.join(input_folder, filename))\n",
    "\n",
    "        if prev_frame is not None:\n",
    "            pixel_diff = compute_pixel_difference(prev_frame, frame)\n",
    "            \n",
    "            hist_diff = compare_histograms(prev_frame, frame)\n",
    "            \n",
    "            if pixel_diff > pixel_diff_threshold or hist_diff < hist_diff_threshold:\n",
    "                print(f\"Scene cut detected at frame {frame_number} (Pixel diff: {pixel_diff}, Hist diff: {hist_diff})\")\n",
    "                scene_cuts.append(frame_number)\n",
    "        \n",
    "        prev_frame = frame\n",
    "        frame_number += 1\n",
    "\n",
    "print(f\"Scene cuts detected at frames: {scene_cuts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58772355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8db3adf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abac0cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "275139e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft cut detected at frame 56\n",
      "Soft cut detected at frame 127\n",
      "Soft cut detected at frame 179\n",
      "Soft cut detected at frame 215\n",
      "Soft cut detected at frame 217\n",
      "Soft cut detected at frame 260\n",
      "Soft cut detected at frame 263\n",
      "Soft cut detected at frame 280\n",
      "Soft cut detected at frame 281\n",
      "Soft cuts detected at frames: [56, 127, 179, 215, 217, 260, 263, 280, 281]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "input_folder = r\"C:\\Users\\Radcoflex-Purchase\\Desktop\\COLLEGE\\SEM 7\\Image and Video Analytics\\lab 4\\cola\"\n",
    "\n",
    "intensity_change_threshold = 20  \n",
    "histogram_similarity_threshold = 0.7 \n",
    "window_size = 20 \n",
    "\n",
    "def compute_average_intensity(frame):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    return np.mean(gray_frame)\n",
    "\n",
    "def compare_histograms(frame1, frame2):\n",
    "    hsv_frame1 = cv2.cvtColor(frame1, cv2.COLOR_BGR2HSV)\n",
    "    hsv_frame2 = cv2.cvtColor(frame2, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    hist_frame1 = cv2.calcHist([hsv_frame1], [0, 1, 2], None, [8, 8, 8], [0, 180, 0, 256, 0, 256])\n",
    "    hist_frame2 = cv2.calcHist([hsv_frame2], [0, 1, 2], None, [8, 8, 8], [0, 180, 0, 256, 0, 256])\n",
    "    \n",
    "    cv2.normalize(hist_frame1, hist_frame1)\n",
    "    cv2.normalize(hist_frame2, hist_frame2)\n",
    "    \n",
    "    return cv2.compareHist(hist_frame1, hist_frame2, cv2.HISTCMP_CORREL)\n",
    "\n",
    "frame_number = 0\n",
    "soft_cuts = []\n",
    "intensities = []\n",
    "\n",
    "for filename in sorted(os.listdir(input_folder)): \n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        frame = cv2.imread(os.path.join(input_folder, filename))\n",
    "\n",
    "        if frame is not None:\n",
    "            avg_intensity = compute_average_intensity(frame)\n",
    "            intensities.append(avg_intensity)\n",
    "\n",
    "            if len(intensities) > window_size:\n",
    "                intensity_diffs = [abs(intensities[i] - intensities[i+1]) for i in range(len(intensities) - 1)]\n",
    "                \n",
    "                mean_intensity_diff = np.mean(intensity_diffs[-window_size:])\n",
    "                median_intensity_diff = np.median(intensity_diffs[-window_size:])\n",
    "\n",
    "                hist_similarity = compare_histograms(frame, cv2.imread(os.path.join(input_folder, sorted(os.listdir(input_folder))[frame_number - 1])))\n",
    "\n",
    "                if mean_intensity_diff < intensity_change_threshold and hist_similarity < histogram_similarity_threshold:\n",
    "                    soft_cuts.append(frame_number - window_size) \n",
    "                    print(f\"Soft cut detected at frame {frame_number - window_size}\")\n",
    "\n",
    "            frame_number += 1\n",
    "\n",
    "print(f\"Soft cuts detected at frames: {soft_cuts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa20e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9441edc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
